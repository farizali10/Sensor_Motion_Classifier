{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Set the warnings to be ignored\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.linear_model  import Ridge,Lasso,RidgeCV, LassoCV, ElasticNet, ElasticNetCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def output_filler(df, path):\n",
    "    # Split the path using the appropriate separator for the current OS\n",
    "    path = os.path.normpath(path)\n",
    "    path_parts = path.split(os.path.sep)\n",
    "\n",
    "    # Get the second-to-last part of the path\n",
    "    output = path_parts[-2]\n",
    "\n",
    "    # Add a new \"Output\" column to the DataFrame and set it to the output value\n",
    "    df[\"Output\"] = output\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th># Task: bending1</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td># Frequency (Hz): 20</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td># Clock (millisecond): 250</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td># Duration (seconds): 120</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td># Columns: time,avg_rss12,var_rss12,avg_rss13,...</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0,39.25,0.43,22.75,0.43,33.75,1.30</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>118750,43.33,0.47,25.00,0.00,30.00,0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>119000,43.50,0.50,25.50,0.50,30.00,0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>119250,43.50,0.50,24.75,0.43,30.00,0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>119500,43.50,0.50,24.33,0.47,30.00,0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>119750,43.50,0.50,24.25,0.43,30.00,0.00</td>\n",
       "      <td>bending1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>484 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      # Task: bending1    Output\n",
       "0                                 # Frequency (Hz): 20  bending1\n",
       "1                           # Clock (millisecond): 250  bending1\n",
       "2                            # Duration (seconds): 120  bending1\n",
       "3    # Columns: time,avg_rss12,var_rss12,avg_rss13,...  bending1\n",
       "4                   0,39.25,0.43,22.75,0.43,33.75,1.30  bending1\n",
       "..                                                 ...       ...\n",
       "479            118750,43.33,0.47,25.00,0.00,30.00,0.00  bending1\n",
       "480            119000,43.50,0.50,25.50,0.50,30.00,0.00  bending1\n",
       "481            119250,43.50,0.50,24.75,0.43,30.00,0.00  bending1\n",
       "482            119500,43.50,0.50,24.33,0.47,30.00,0.00  bending1\n",
       "483            119750,43.50,0.50,24.25,0.43,30.00,0.00  bending1\n",
       "\n",
       "[484 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How output_filler works\n",
    "path = \"D:/Data-Science-D-drive/Datasets-D-drive/sensor_placement/bending1/dataset1.csv\"\n",
    "df = pd.read_csv(\"D:/Data-Science-D-drive/Datasets-D-drive/sensor_placement/bending1/dataset1.csv\", sep = \"\\t\")\n",
    "output_filler(df,path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling Output Column and Creating New DatFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the logging module\n",
    "# Remove or disable existing logging handlers\n",
    "root_logger = logging.getLogger()\n",
    "for handler in root_logger.handlers:\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "# Configure the logging module with a time format\n",
    "log_filename = \"error.log\"\n",
    "log_level = logging.DEBUG\n",
    "logging.basicConfig(filename=log_filename, level=log_level, format='%(asctime)s [%(levelname)s] %(message)s')  # Save errors+info to a file\n",
    "\n",
    "op_filepath_list = []\n",
    "        \n",
    "try:\n",
    "    logging.info(f\"Reading Main Folder\")\n",
    "    main_folder_path = \"D:\\Data-Science-D-drive\\Datasets-D-drive\\sensor_placement\"\n",
    "    main_folder_path = os.path.normpath(main_folder_path)\n",
    "    \n",
    "    try:\n",
    "        ##### LISTING AND STORING SUB-FOLDERS CONTENTS PRESENT IN MAIN FOLDER PATH I.E. BENDING1, BENDING2, SITTING, ETC ... #####\n",
    "        contents = os.listdir(main_folder_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error listing contents in {main_folder_path}: {e}\")\n",
    "\n",
    "    else:\n",
    "        for paths in contents:\n",
    "            ##### STORING SUB-FOLDERS PATHS PRESENT IN MAIN FOLDER PATH #####\n",
    "            sub_folder_path = os.path.join(main_folder_path, paths)\n",
    "\n",
    "            try:\n",
    "                #### LISTING CONTENTS PRESENT IN SUB-FOLDERS PATH I.E. DATASET1, DATASET2, DATASET3, ETC... ####\n",
    "                sub_folder_contents = os.listdir(sub_folder_path)\n",
    "                    \n",
    "                # CREATING \"OUTPUT\" DIRECTORY IN EACH SUB-FOLDERS TO STORE OUTPUT CSV #   \n",
    "                directory_name = \"output\"\n",
    "\n",
    "                output_path = os.path.join(sub_folder_path, directory_name)\n",
    "                os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error listing contents in {sub_folder_path}: {e}\")\n",
    "\n",
    "            else:\n",
    "                path_list = []\n",
    "\n",
    "                for item in sub_folder_contents:\n",
    "                    #### STORING FILE'S PATH PRESENT IN SUB-FOLDERS I.E. DATASET1, DATASET2, DATASET3, ETC... ####\n",
    "                    file_path = os.path.join(sub_folder_path, item)\n",
    "                    path_list.append(file_path)\n",
    "                            \n",
    "                ### READING FILE PATHS IN SUB-FOLDERS ###\n",
    "                for path in path_list:\n",
    "                    logging.info(\"=\"*100)\n",
    "                    try:\n",
    "                        csv_content = pd.read_csv(path, sep=\",\", skiprows=4, header=0)\n",
    "                        csv_content = csv_content.reset_index(drop=True)\n",
    "                        csv_content = output_filler(csv_content, path)\n",
    "\n",
    "                        logging.info(f\"Processing {path}\")\n",
    "                        logging.info(csv_content.head(2).to_string(index=False))\n",
    "\n",
    "                        ### STORING NEW FILE'S CREATED IN OUTPUT FOLDER I.E. NEW_DATASET1, NEW_DATASET2, NEW_DATASET3, ETC... ####\n",
    "                        try:\n",
    "                            file_name = os.path.split(path)\n",
    "                            file_name = file_name[-1].split(\".\")[0]\n",
    "                        \n",
    "\n",
    "                            logging.info(\"Creating Output File Path\")\n",
    "                            output_file_path = os.path.join(output_path, f\"new_{file_name}.csv\")\n",
    "                            op_filepath_list.append(output_file_path)\n",
    "                            csv_content.to_csv(output_file_path)\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Error creating Output File Path for {file_name}: {e}\")\n",
    "\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error Reading contents in {path}: {e}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"D:/Data-Science-D-drive/Datasets-D-drive/sensor_placement/bending1/output\"\n",
    "\n",
    "folder_path = os.path.normpath(folder_path)\n",
    "\n",
    "# List all files and directories in the folder\n",
    "contents = os.listdir(folder_path)\n",
    "\n",
    "path_list = []\n",
    "\n",
    "# Store the paths\n",
    "for item in contents:\n",
    "    path_list.append(os.path.join(folder_path, item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset1.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset2.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset3.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset4.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset5.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset6.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset7.csv']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "# Remove or disable existing logging handlers\n",
    "root_logger = logging.getLogger()\n",
    "for handler in root_logger.handlers:\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "# Configure the logging module with a time format\n",
    "log_filename = \"concatenation.log\"\n",
    "log_level = logging.DEBUG\n",
    "logging.basicConfig(filename=log_filename, level=log_level, format='%(asctime)s [%(levelname)s] %(message)s')\n",
    "\n",
    "output_path = r\"D:\\Data-Science-D-drive\\Datasets-D-drive\\sensor_placement\"\n",
    "\n",
    "contents = os.list\n",
    "for path in path_list:\n",
    "    try:\n",
    "        # List all files and directories in the folder\n",
    "        contents = os.listdir(output_path)\n",
    "\n",
    "        path_list = []\n",
    "\n",
    "        # Store the paths\n",
    "        for item in contents:\n",
    "            path_list.append(os.path.join(output_path, item))\n",
    "\n",
    "        final_df = pd.DataFrame()\n",
    "        for path in path_list:\n",
    "            df = pd.read_csv(path)\n",
    "            df = df.reset_index(drop=True)\n",
    "\n",
    "            final_df = pd.concat([final_df,df], ignore_index=True)\n",
    "            \n",
    "            # Get the second-to-last part of the path\n",
    "            path_parts = path.split(os.path.sep)\n",
    "            output_fname = path_parts[-1]\n",
    "            print(f\"{output_fname} Shape = {df.shape}\")\n",
    "\n",
    "        final_df_path = os.path.join(output_path, \"final_df.csv\")\n",
    "\n",
    "        # Extract the first column as a DataFrame using iloc\n",
    "        first_column_df = final_df.iloc[:, [0]]\n",
    "        final_df = final_df.drop(first_column_df, axis=1)\n",
    "\n",
    "        final_df.to_csv(final_df_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error processing {path}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset1.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset2.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset3.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset4.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset5.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset6.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\dataset7.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset1.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset2.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset3.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset4.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset5.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset6.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\new_dataset7.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op_filepath_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for output_path in op_filepath_list:\n",
    "    try:\n",
    "        df[i] = pd.read_csv(output_path)\n",
    "        logging.info(f\"Reading Files: {output_path}\")\n",
    "\n",
    "        logging.info(f\"Concatenating Datasets\")\n",
    "\n",
    "        final_df = \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error Reading Paths {output_path}: \\n\\t\\t\\t\\t\\t\\t{e}\")\n",
    "        logging.info(\"-\"*100)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset1.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset2.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset3.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset4.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset5.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset6.csv',\n",
       " 'D:\\\\Data-Science-D-drive\\\\Datasets-D-drive\\\\sensor_placement\\\\bending1\\\\output\\\\new_dataset7.csv']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3360, 9)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3360 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0\n",
       "0              0\n",
       "1              1\n",
       "2              2\n",
       "3              3\n",
       "4              4\n",
       "...          ...\n",
       "3355         475\n",
       "3356         476\n",
       "3357         477\n",
       "3358         478\n",
       "3359         479\n",
       "\n",
       "[3360 rows x 1 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the first column as a DataFrame using iloc\n",
    "first_column_df = df.iloc[:, [0]]\n",
    "\n",
    "# Drop the first_column_df DataFrame\n",
    "df = df.drop(first_column_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
